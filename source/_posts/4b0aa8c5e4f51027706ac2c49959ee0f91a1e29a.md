---
title: 4b0aa8c5e4f51027706ac2c49959ee0f91a1e29
date: 2017-03-14 11:56:34
tags: treeboosting
---
# 原理介绍
  分类器是在机器学期领域中对数据进行统计、分类及预测的一类重要方法，各种不同的分类器被广泛应用于工业界及各类数据挖掘的比赛中。目前已知的分类器方法有一大类主要基于集成学习，基于这个思想目前已知的有引导聚集算法或装袋法(Bagging)、自适应增强算法(Adaboost)、多重增强算法(Multiboost)、梯度增强算法(Gradient Boosting)和极限梯度增强算法(XGBoost)。本文将先介绍引导聚集算法和自适应增强算法作为引入，再重点介绍本文所使用的极限梯度增强算法。
## 集成学习方法概述
对于一个分类器来说，如果其模型结构较为复杂，则其很容易适应当前数据，即对于当前数据拟合有很好的效果，误差较小，但是这样很容易造成对数据的过度拟合(Overfitting)，不利于对于未知的数据进行预测。反之，如果一个模型结构较为简单，则虽然不至于对训练数据过度拟合，但有可能在训练集中产生较大的误差，这同样不利于分类器对未知的数据进行预测。集成学习方法综合了以上两个方向的有点来做机器学期，其目标是在模型的复杂度和数据模型拟合和准确率之间做一个最优的平衡，以达到优秀的预测效果。
对于一个给定的数据集，集成学习方法往往先将这个数据集分割成N个数据子集，在对这N个子集中的数据分别做训练调节分类器的结构和参数，形成一个弱分类器，最后对于一个未知数据，集成学习方法用这个N子集所预测出的N的结果用事先约定好的方法做集成，做出最终预测。
<!-- more -->
### 自引导抽样法
这类方法是对于一个给定的数据集S, 生成N个数据子集的一类经典方法。自引导抽样法是一个有放回的抽样法，在假定每个元素都处于连续均匀分布情况下对每个元素进行等概率抽样，抽完样后将元素放回。例如，对于一个给定的数据集$D=\\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\\}$，其中$x_i\in{R^{d}}, y_i\in{R}, |D|=m$， 数据集中有m个元素，在经过k次、每次抽取n的元素的抽样后，对于第i个数据集。对于某个数据子集，由于它是由有放回抽样的方法获取的，所以数据子集中的元素可能重复，但是数据子集中的每一个元素都属于原来给定的数据集$D$。
在这个有m的元素的数据集D中，每个元素每次被抽中的概率为$1\over m$, 那么每个元素不被抽中的概率就是$1-{1\over m}$, 所以在经过足够多次的抽样后，每个元素仍不被选进用于训练的数据子集的概率为$\lim{m\to \infty}{(1-{1\over m})}^{m} = {1\over e} \approx 0.368$。换言之，利用自引导抽样法可以将约$63.2\%$的原始数据作为训练集，而将其余的作为测试集。
自引导抽样法是生成训练数据的一种方法，本文其余部分生成数据子集的方法包括但不限于此方法。
### 引导聚集算法
引导聚集算法是一个相对基本的增强学习方法，其基本原理是先利用自引导抽样法生成N个数据子集，再对每个数据子集分别训练分类器，当有需要预测的数据时，算法会让事先训练好的N个数据子集对应的N个分类器分别做预测，最后通过类似投票的方式产生最终结果。当对于某个特定的数据子集进行训练时，可以采用类似于L2范式的标准设计目标函数，测量训练目标与设计目标的欧几里得距离，目标函数的值越小说明训练效果越好。例如，对于第$i$个数据子集而言，其目标函数可以设计成$\sum_{i}^{n}{1\over 2}{(y_i-\hat{y_i})}^2$。对于预测结果，可以让所有的弱分类器对结果进行等权重投票，得票最高的数据即为最终结果。
### 自适应增强算法
自适应增强算法是基于引导聚集算法的改进，它的工作原理是对于不同的元素根据分类或预测错误率设定抽样是的权重。例如在对第i个数据子集的预测完成后，算法会对第i次的预测进行评估，并筛选出预测结果有有误的部分，根据误差情况在将样本放回时适当地增加这些被错误预测的样本的抽样概率，这样在对第i+1次数据子集进行训练时，在第i轮被错误预测的数据会被重点训练，以此增强训练效果。例如，在第i轮训练时，第2、3、5号样本被错误预测，则本轮训练结束后在将样本放回时会增加2、3、5号样本被抽中的概率。在第i+1轮训练时，第2、3、5号样本就有很大的概率成为第i+1轮数据子集中的元素，这样第i+1轮训练出类来的分类器会适当地提高对第2、3、5号样本预测的精确度，而在第i+1轮训练结束后被错误预测的样本又会有很大的概率出现在下一轮的数据子集中。
## 极限增强算法
### 核心算法
这个算法是由
### 其他改进设计